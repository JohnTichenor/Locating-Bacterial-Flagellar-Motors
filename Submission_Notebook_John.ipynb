{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 91249,
          "databundleVersionId": 11218843,
          "isSourceIdPinned": false,
          "sourceType": "competition"
        },
        {
          "sourceId": 224916709,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 225054260,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnTichenor/Locating-Bacterial-Flagellar-Motors/blob/main/Submission_Notebook_John.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "#import kagglehub\n",
        "#kagglehub.login()\n"
      ],
      "metadata": {
        "id": "wJJkGWs-J7U_"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 1
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "#byu_locating_bacterial_flagellar_motors_2025_path = kagglehub.competition_download('byu-locating-bacterial-flagellar-motors-2025')\n",
        "#andrewjdarley_ultralytics_for_offline_install_path = kagglehub.notebook_output_download('andrewjdarley/ultralytics-for-offline-install')\n",
        "#andrewjdarley_train_yolo_path = kagglehub.notebook_output_download('andrewjdarley/train-yolo')\n",
        "\n",
        "#print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "J7fZyF4LJ7VA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BYU Locating Flagellar Motors\n",
        "\n",
        "## Submission Generation Notebook\n",
        "\n",
        "This is the fourth and final notebook in a series for the BYU Locating Bacterial Flagellar Motors 2025 Kaggle challenge. This notebook creates predictions on test data and generates the competition submission file.\n",
        "\n",
        "### Notebook Series:\n",
        "1. **[Parse Data](https://www.kaggle.com/code/andrewjdarley/parse-data)**: Extracting and preparing 2D slices containing motors to make a YOLO dataset\n",
        "2. **[Visualize Data](https://www.kaggle.com/code/andrewjdarley/visualize-data)**: Exploratory data analysis and visualization of annotated motor locations\n",
        "3. **[Train YOLO](https://www.kaggle.com/code/andrewjdarley/train-yolo)**: Fine tuning an YOLOv8 object detection model on the prepared dataset\n",
        "4. **Submission Notebook (Current)**: Running inference and generating submission files\n",
        "\n",
        "## Important: Offline Execution\n",
        "This notebook is designed to run in an offline environment. The Ultralytics YOLOv8 package has been installed using the offline installation method from [this reference notebook](https://www.kaggle.com/code/itsuki9180/ultralytics-for-offline-install). This implementation was brilliant. I use my own copy as input that works effectively the same as the original.\n",
        "\n",
        "## About this Notebook\n",
        "\n",
        "This submission notebook implements an optimized inference pipeline that:\n",
        "\n",
        "1. **Model Loading**: Loads the best trained YOLOv8 weights from the training notebook\n",
        "2. **GPU Optimization**: Configures CUDA optimizations, half-precision inference, and memory management\n",
        "3. **Parallel Processing**: Uses CUDA streams and batch processing for efficient GPU utilization\n",
        "4. **3D Detection**: Processes each slice to locate motors\n",
        "5. **Non-Maximum Suppression**: Applies 3D NMS to cluster and merge detections across slices\n",
        "6. **Submission Generation**: Creates the final CSV file with predicted motor coordinates\n",
        "\n",
        "The code includes advanced optimizations like dynamic batch sizing based on available GPU memory, preloading batches while processing the current batch, and GPU profiling to monitor performance. The CONCENTRATION parameter can be adjusted to trade off between processing speed and detection accuracy. The only reason you'd ever modify CONCENTRATION is just to verify submission capability since full submission takes a few hours."
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "sU_tsw_6J7VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar xfvz /kaggle/input/ultralytics-for-offline-install/archive.tar.gz\n",
        "# !pip install --no-index --find-links=./packages ultralytics\n",
        "# !rm -rf ./packages"
      ],
      "metadata": {
        "trusted": true,
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2025-03-03T17:16:40.916518Z",
          "iopub.execute_input": "2025-03-03T17:16:40.9174Z",
          "iopub.status.idle": "2025-03-03T17:17:35.355086Z",
          "shell.execute_reply.started": "2025-03-03T17:16:40.917369Z",
          "shell.execute_reply": "2025-03-03T17:17:35.354105Z"
        },
        "id": "vKQcgNmmJ7VB"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount collab"
      ],
      "metadata": {
        "id": "YGjo9G6UN7Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQpvH_KwN6sE",
        "outputId": "b31785a9-b07a-42d6-f3e1-4bdec56c6a39"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "import threading\n",
        "import time\n",
        "from contextlib import nullcontext\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from torchvision import transforms\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define paths\n",
        "# data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n",
        "# test_dir = os.path.join(data_path, \"test\")\n",
        "# submission_path = \"/kaggle/working/submission.csv\"\n",
        "\n",
        "test_dir = \"/content/drive/MyDrive/Phys417FinalProject/BacterialFlagellarMotorsData/test\"\n",
        "submission_path = \"/content/drive/MyDrive/Phys417FinalProject/BacterialFlagellarMotorsData/submission_2.csv\"\n",
        "\n",
        "# Model path - adjust if your best model is saved in a different location\n",
        "model_path = \"/content/drive/MyDrive/Phys417FinalProject/BacterialFlagellarMotorsData/fasterrcnn_motor_detector_2.pth\"\n",
        "NUM_CLASSES = 2  # Example: 1 class + background; change as needed\n",
        "\n",
        "\n",
        "# Detection parameters\n",
        "CONFIDENCE_THRESHOLD = 0.45  # Lower threshold to catch more potential motors\n",
        "MAX_DETECTIONS_PER_TOMO = 3  # Keep track of top N detections per tomogram\n",
        "NMS_IOU_THRESHOLD = 0.2  # Non-maximum suppression threshold for 3D clustering\n",
        "CONCENTRATION = 1 # ONLY PROCESS 1/20 slices for fast submission\n",
        "\n",
        "# GPU profiling context manager\n",
        "class GPUProfiler:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.start_time = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        self.start_time = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        elapsed = time.time() - self.start_time\n",
        "        print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n",
        "\n",
        "# Check GPU availability and set up optimizations\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "BATCH_SIZE = 8  # Default batch size, will be adjusted dynamically if GPU available\n",
        "\n",
        "if device.startswith('cuda'):\n",
        "    # Set CUDA optimization flags\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True  # Allow TF32 on Ampere GPUs\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "    # Print GPU info\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
        "    print(f\"Using GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n",
        "\n",
        "    # Get available GPU memory and set batch size accordingly\n",
        "    free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n",
        "    BATCH_SIZE = max(8, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n",
        "    print(f\"Dynamic batch size set to {BATCH_SIZE} based on {free_mem:.2f}GB free memory\")\n",
        "else:\n",
        "    print(\"GPU not available, using CPU\")\n",
        "    BATCH_SIZE = 4  # Reduce batch size for CPU\n",
        "\n",
        "\n",
        "def load_and_preprocess_image(img_path):\n",
        "    # Loads image as PIL, converts to tensor, normalizes as expected by torchvision models\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return preprocess(img)\n",
        "\n",
        "\n",
        "def normalize_slice(slice_data):\n",
        "    \"\"\"\n",
        "    Normalize slice data using 2nd and 98th percentiles for better contrast\n",
        "    \"\"\"\n",
        "    p2 = np.percentile(slice_data, 2)\n",
        "    p98 = np.percentile(slice_data, 98)\n",
        "    clipped_data = np.clip(slice_data, p2, p98)\n",
        "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
        "    return np.uint8(normalized)\n",
        "\n",
        "def preload_image_batch(file_paths):\n",
        "    \"\"\"Preload a batch of images to CPU memory\"\"\"\n",
        "    images = []\n",
        "    for path in file_paths:\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            # Try with PIL as fallback\n",
        "            img = np.array(Image.open(path))\n",
        "        images.append(img)\n",
        "    return images\n",
        "\n",
        "def process_tomogram(tomo_id, model, index=0, total=1):\n",
        "    print(f\"Processing tomogram {tomo_id} ({index}/{total})\")\n",
        "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
        "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
        "\n",
        "    selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * CONCENTRATION))\n",
        "    selected_indices = np.round(selected_indices).astype(int)\n",
        "    slice_files = [slice_files[i] for i in selected_indices]\n",
        "\n",
        "    print(f\"Processing {len(slice_files)} out of {len(os.listdir(tomo_dir))} slices based on CONCENTRATION={CONCENTRATION}\")\n",
        "\n",
        "    all_detections = []\n",
        "\n",
        "    for idx, slice_file in enumerate(slice_files):\n",
        "        img_path = os.path.join(tomo_dir, slice_file)\n",
        "        slice_num = int(slice_file.split('_')[1].split('.')[0])\n",
        "\n",
        "        # Preprocess for Faster R-CNN\n",
        "        image_tensor = load_and_preprocess_image(img_path).to(device).unsqueeze(0)  # shape (1, C, H, W)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(image_tensor)\n",
        "\n",
        "        boxes = outputs[0]['boxes'].cpu().numpy()  # (N, 4)\n",
        "        scores = outputs[0]['scores'].cpu().numpy()  # (N,)\n",
        "        labels = outputs[0]['labels'].cpu().numpy()  # (N,)\n",
        "\n",
        "        # Filter out detections below confidence threshold and (optionally) by class\n",
        "        for box, score, label in zip(boxes, scores, labels):\n",
        "            if score >= CONFIDENCE_THRESHOLD:\n",
        "                x1, y1, x2, y2 = box\n",
        "                x_center = (x1 + x2) / 2\n",
        "                y_center = (y1 + y2) / 2\n",
        "\n",
        "                all_detections.append({\n",
        "                    'z': round(slice_num),\n",
        "                    'y': round(y_center),\n",
        "                    'x': round(x_center),\n",
        "                    'confidence': float(score)\n",
        "                })\n",
        "\n",
        "    # Non-maximum suppression as before\n",
        "    final_detections = perform_3d_nms(all_detections, NMS_IOU_THRESHOLD)\n",
        "    final_detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "    if not final_detections:\n",
        "        return {\n",
        "            'tomo_id': tomo_id,\n",
        "            'Motor axis 0': -1,\n",
        "            'Motor axis 1': -1,\n",
        "            'Motor axis 2': -1\n",
        "        }\n",
        "\n",
        "    best_detection = final_detections[0]\n",
        "    return {\n",
        "        'tomo_id': tomo_id,\n",
        "        'Motor axis 0': round(best_detection['z']),\n",
        "        'Motor axis 1': round(best_detection['y']),\n",
        "        'Motor axis 2': round(best_detection['x'])\n",
        "    }\n",
        "\n",
        "\n",
        "def perform_3d_nms(detections, iou_threshold):\n",
        "    \"\"\"\n",
        "    Perform 3D Non-Maximum Suppression on detections to merge nearby motors\n",
        "    \"\"\"\n",
        "    if not detections:\n",
        "        return []\n",
        "\n",
        "    # Sort by confidence (highest first)\n",
        "    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "    # List to store final detections after NMS\n",
        "    final_detections = []\n",
        "\n",
        "    # Define 3D distance function\n",
        "    def distance_3d(d1, d2):\n",
        "        return np.sqrt((d1['z'] - d2['z'])**2 +\n",
        "                       (d1['y'] - d2['y'])**2 +\n",
        "                       (d1['x'] - d2['x'])**2)\n",
        "\n",
        "    # Maximum distance threshold (based on box size and slice gap)\n",
        "    box_size = 24  # Same as annotation box size\n",
        "    distance_threshold = box_size * iou_threshold\n",
        "\n",
        "    # Process each detection\n",
        "    while detections:\n",
        "        # Take the detection with highest confidence\n",
        "        best_detection = detections.pop(0)\n",
        "        final_detections.append(best_detection)\n",
        "\n",
        "        # Filter out detections that are too close to the best detection\n",
        "        detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n",
        "\n",
        "    return final_detections\n",
        "\n",
        "def debug_image_loading(tomo_id):\n",
        "    \"\"\"\n",
        "    Debug function to check image loading\n",
        "    \"\"\"\n",
        "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
        "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
        "\n",
        "    if not slice_files:\n",
        "        print(f\"No image files found in {tomo_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(slice_files)} image files in {tomo_dir}\")\n",
        "    sample_file = slice_files[len(slice_files)//2]  # Middle slice\n",
        "    img_path = os.path.join(tomo_dir, sample_file)\n",
        "\n",
        "    # Try different loading methods\n",
        "    try:\n",
        "        # Method 1: PIL\n",
        "        img_pil = Image.open(img_path)\n",
        "        img_array_pil = np.array(img_pil)\n",
        "        print(f\"PIL Image shape: {img_array_pil.shape}, dtype: {img_array_pil.dtype}\")\n",
        "\n",
        "        # Method 2: OpenCV\n",
        "        img_cv2 = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        print(f\"OpenCV Image shape: {img_cv2.shape}, dtype: {img_cv2.dtype}\")\n",
        "\n",
        "        # Method 3: Convert to RGB\n",
        "        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "        print(f\"OpenCV RGB Image shape: {img_rgb.shape}, dtype: {img_rgb.dtype}\")\n",
        "\n",
        "        print(\"Image loading successful!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "\n",
        "def generate_submission():\n",
        "    \"\"\"\n",
        "    Main function to generate the submission file\n",
        "    \"\"\"\n",
        "    # Get list of test tomograms\n",
        "    test_tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n",
        "    total_tomos = len(test_tomos)\n",
        "\n",
        "    print(f\"Found {total_tomos} tomograms in test directory\")\n",
        "\n",
        "    # Debug image loading for the first tomogram\n",
        "    if test_tomos:\n",
        "        debug_image_loading(test_tomos[0])\n",
        "\n",
        "    # Clear GPU cache before starting\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=False, num_classes=NUM_CLASSES)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Loaded Faster R-CNN model from {model_path} onto {device}\")\n",
        "\n",
        "    # Process tomograms with parallelization\n",
        "    results = []\n",
        "    motors_found = 0\n",
        "\n",
        "    # Using ThreadPoolExecutor with max_workers=1 since each worker uses the GPU already\n",
        "    # and we're parallelizing within each tomogram processing\n",
        "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
        "        future_to_tomo = {}\n",
        "\n",
        "        # Submit all tomograms for processing\n",
        "        for i, tomo_id in enumerate(test_tomos, 1):\n",
        "            future = executor.submit(process_tomogram, tomo_id, model, i, total_tomos)\n",
        "            future_to_tomo[future] = tomo_id\n",
        "\n",
        "        # Process completed futures as they complete\n",
        "        for future in future_to_tomo:\n",
        "            tomo_id = future_to_tomo[future]\n",
        "            try:\n",
        "                # Clear CUDA cache between tomograms\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "                result = future.result()\n",
        "                results.append(result)\n",
        "\n",
        "                # Update motors found count\n",
        "                has_motor = not pd.isna(result['Motor axis 0'])\n",
        "                if has_motor:\n",
        "                    motors_found += 1\n",
        "                    print(f\"Motor found in {tomo_id} at position: \"\n",
        "                          f\"z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}\")\n",
        "                else:\n",
        "                    print(f\"No motor detected in {tomo_id}\")\n",
        "\n",
        "                print(f\"Current detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {tomo_id}: {e}\")\n",
        "                # Create a default entry for failed tomograms\n",
        "                results.append({\n",
        "                    'tomo_id': tomo_id,\n",
        "                    'Motor axis 0': -1,\n",
        "                    'Motor axis 1': -1,\n",
        "                    'Motor axis 2': -1\n",
        "                })\n",
        "\n",
        "    # Create submission dataframe\n",
        "    submission_df = pd.DataFrame(results)\n",
        "\n",
        "    # Ensure proper column order\n",
        "    submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]\n",
        "\n",
        "    # Save the submission file\n",
        "    submission_df.to_csv(submission_path, index=False)\n",
        "\n",
        "    print(f\"\\nSubmission complete!\")\n",
        "    print(f\"Motors detected: {motors_found}/{total_tomos} ({motors_found/total_tomos*100:.1f}%)\")\n",
        "    print(f\"Submission saved to: {submission_path}\")\n",
        "\n",
        "    # Display first few rows of submission\n",
        "    print(\"\\nSubmission preview:\")\n",
        "    print(submission_df.head())\n",
        "\n",
        "    return submission_df\n",
        "\n",
        "# Run the submission pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Time entire process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Generate submission\n",
        "    submission = generate_submission()\n",
        "\n",
        "    # Print total execution time\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\nTotal execution time: {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-03T17:20:26.73762Z",
          "iopub.execute_input": "2025-03-03T17:20:26.737979Z",
          "iopub.status.idle": "2025-03-03T17:21:16.998571Z",
          "shell.execute_reply.started": "2025-03-03T17:20:26.737952Z",
          "shell.execute_reply": "2025-03-03T17:21:16.997779Z"
        },
        "id": "8W9o6A73J7VB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bee675b-32d3-437f-ef00-b72c10aecf2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: NVIDIA A100-SXM4-40GB with 42.47 GB memory\n",
            "Dynamic batch size set to 32 based on 42.47GB free memory\n",
            "Found 3 tomograms in test directory\n",
            "Found 500 image files in /content/drive/MyDrive/Phys417FinalProject/BacterialFlagellarMotorsData/test/tomo_003acc\n",
            "PIL Image shape: (1912, 1847), dtype: uint8\n",
            "OpenCV Image shape: (1912, 1847), dtype: uint8\n",
            "OpenCV RGB Image shape: (1912, 1847, 3), dtype: uint8\n",
            "Image loading successful!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 223MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Faster R-CNN model from /content/drive/MyDrive/Phys417FinalProject/BacterialFlagellarMotorsData/fasterrcnn_motor_detector_2.pth onto cuda:0\n",
            "Processing tomogram tomo_003acc (1/3)\n",
            "Processing 500 out of 500 slices based on CONCENTRATION=1\n",
            "Processing tomogram tomo_00e047 (2/3)\n",
            "Motor found in tomo_003acc at position: z=-1, y=-1, x=-1\n",
            "Current detection rate: 1/1 (100.0%)\n",
            "Processing 300 out of 300 slices based on CONCENTRATION=1\n",
            "Processing tomogram tomo_01a877 (3/3)Motor found in tomo_00e047 at position: z=170, y=548, x=607\n",
            "Current detection rate: 2/2 (100.0%)\n",
            "\n",
            "Processing 300 out of 300 slices based on CONCENTRATION=1\n",
            "Motor found in tomo_01a877 at position: z=138, y=639, x=286\n",
            "Current detection rate: 3/3 (100.0%)\n",
            "\n",
            "Submission complete!\n",
            "Motors detected: 3/3 (100.0%)\n",
            "Submission saved to: /content/drive/MyDrive/Phys417FinalProject/BacterialFlagellarMotorsData/submission_2.csv\n",
            "\n",
            "Submission preview:\n",
            "       tomo_id  Motor axis 0  Motor axis 1  Motor axis 2\n",
            "0  tomo_003acc            -1            -1            -1\n",
            "1  tomo_00e047           170           548           607\n",
            "2  tomo_01a877           138           639           286\n",
            "\n",
            "Total execution time: 393.70 seconds (6.56 minutes)\n"
          ]
        }
      ],
      "execution_count": 5
    }
  ]
}